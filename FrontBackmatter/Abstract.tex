\chapter*{Abstract}
Over the last decades, several billion Web pages have been made available on the Web. 
The growing amount of Web data provides the world's largest collection of knowledge.\footnote{\url{http://www.worldwidewebsize.com/}} 
Most of this full-text data like blogs, news or encyclopaedic information is textual in nature.
However, the increasing amount of structured respectively semantic data\footnote{\url{http://stats.lod2.eu/}} available on the Web fosters new search paradigms.
These novel paradigms ease the development of natural language interfaces which enable end-users to easily access and benefit from large amounts of data without the need to understand the underlying structures or algorithms.

Building a natural language \ac{QA} system over heterogeneous, Web-based knowledge sources requires various building blocks.
These building components include (a) knowledge extraction approaches over textual data such as blogs, news, templated websites or product descriptions to capture the semantics of the content of a document, (b) linguistic parsing modules for natural language and (c) efficient query execution and ranking functions.
However, existing knowledge extraction building  blocks lack comparable evaluation settings, performance or quality.{\let\thefootnote\relax\footnote{The author will make use of the we-form as narrative.}}
In this thesis, three main research challenges are identified and addressed:
\begin{enumerate}[topsep=0pt,itemsep=-1ex,partopsep=1ex,parsep=1ex]
\item 
The ongoing transition from the current \emph{Document Web} of textual data to the \emph{Web of Data} requires scalable and accurate approaches for the extraction of structured data in \ac{RDF} from Web-based documents.
We address this key step for bridging the \emph{Semantic Gap}, i.e., extracting RDF from text, with three approaches.
First, this thesis presents CETUS, an approach for recognizing entity types in textual documents to populate RDF knowledge bases. 
Second, we describe the knowledge base-agnostic, multi-lingual, high-quality and efficient named entity disambiguation framework AGDISTIS.
Third, we tackle the scalable extraction of consistent \ac{RDF} data from highly templated websites via our framework REX.
\item 
The need to bridge between the textual Document Web and the structured data on the Web of Data has led to the development of a considerable number of annotation tools and frameworks. 
However, these approaches are currently hard to compare since the published evaluation results are calculated on diverse datasets and evaluated based on different measures
The resulting \emph{Evaluation Gap} is tackled by a novel set of benchmarking corpora as well as with GERBIL, our evaluation framework for semantic entity annotation. 
The rationale behind our framework is to provide developers, end users and researchers with easy-to-use interfaces that allow for the agile, fine-grained and uniform evaluation of annotation approaches on multiple datasets.
\item 
The decentral architecture behind both Webs generated a distributed information landscape across data sources with varying structure. 
Furthermore, current keyword-based search paradigms contradict the human demand for expressing information needs in natural language.
Especially, complex information relationships are often expressed as complex questions by humans.
These observations describe an \emph{Information Gap}, i.e., the user generated demand for natural language interfaces based on the structured Web of Data and the Document Web.
Thus, we introduce HAWK, a novel natural language search framework for hybrid \ac{QA}. 
Our framework is able to combine structured and textual data sources to answer complex natural language questions.
\end{enumerate}
